set_failed_anchor: &set_failed
  do:
  - task: on_failure_set_failed
    tags: ["ccp"]
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: pivotaldata/ccp
          tag: "7"
      inputs:
        - name: ccp_src
        - name: terraform
      run:
        path: 'ccp_src/aws/ccp_failed_test.sh'
      params:
        AWS_ACCESS_KEY_ID: {{tf-machine-access-key-id}}
        AWS_SECRET_ACCESS_KEY: {{tf-machine-secret-access-key}}
        AWS_DEFAULT_REGION: {{tf-machine-region}}
        BUCKET_PATH: clusters/
        BUCKET_NAME: {{tf-bucket-name}}
resource_types:

- name: terraform
  type: docker-image
  source:
    repository: ljfranklin/terraform-resource

resources:
- name: ccp_src
  type: git
  source:
    branch: {{ccp-git-branch}}
    private_key: {{ccp-git-key}}
    uri: {{ccp-git-remote}}
    tag_filter: {{ccp-tag-filter}}

- name: terraform
  type: terraform
  source:
    env:
      AWS_ACCESS_KEY_ID: {{tf-machine-access-key-id}}
      AWS_SECRET_ACCESS_KEY: {{tf-machine-secret-access-key}}
    storage:
      access_key_id: {{tf-machine-access-key-id}}
      secret_access_key: {{tf-machine-secret-access-key}}
      region_name: {{aws-region}}
      # This is not parameterized, on purpose. All tfstates will go to this spot,
      # and different teams will place there clusters' tfstate files under different paths
      bucket: gpdb5-pipeline-dynamic-terraform
      bucket_path: clusters/

- name: perf_src
  type: git
  source:
    branch: dev/pg_upgrade
    private_key: {{perf-git-key}}
    uri: {{perf-git-remote}}
    ignore_paths:
    - README*

- name: gpdb_src
  type: git
  source:
    branch: {{gpdb-git-branch}}
    uri: {{gpdb-git-remote}}
    ignore_paths:
    - gpdb-doc/*
    - README*

- name: gpaddon_src
  type: git
  source:
    branch: {{gpaddon-git-branch}}
    private_key: {{gpaddon-git-key}}
    uri: {{gpaddon-git-remote}}

- name: centos-gpdb-dev-6
  type: docker-image
  source:
    repository: pivotaldata/centos-gpdb-dev
    tag: '6-gcc6.2-llvm3.7'

- name: bin_gpdb4_centos6
  type: s3
  source:
    access_key_id: {{gpdb4-bucket-access-key-id}}
    bucket: {{gpdb4-bucket-name}}
    region_name: {{aws-region}}
    secret_access_key: {{gpdb4-bucket-secret-access-key}}
    versioned_file: bin_gpdb_centos/bin_gpdb.tar.gz

- name: bin_gpdb5_centos6
  type: s3
  source:
    access_key_id: {{ccp-gpdb-binary-bucket-access-key-id}}
    bucket: {{ccp-gpdb-binary-bucket-name}}
    region_name: {{aws-region}}
    secret_access_key: {{ccp-gpdb-binary-bucket-secret-access-key}}
    versioned_file: bin_gpdb_centos6/bin_gpdb.tar.gz

- name: bin_gpdb6_centos6
  type: s3
  source:
    access_key_id: {{bucket-access-key-id}}
    bucket: {{bucket-name}}
    region_name: {{aws-region}}
    secret_access_key: {{bucket-secret-access-key}}
    versioned_file: bin_gpdb_centos/bin_gpdb.tar.gz

ccp_create_params_anchor: &ccp_default_params
  action: create
  delete_on_failure: true
  generate_random_name: true
  terraform_source: ccp_src/aws/

ccp_vars_anchor: &ccp_default_vars
  aws_instance-node-instance_type: t2.medium
  aws_ebs_volume_type: standard
  platform: centos6

ccp_destroy_anchor: &ccp_destroy
  put: terraform
  tags: ["ccp"]
  params:
    action: destroy
    env_name_file: terraform/name
    terraform_source: ccp_src/aws/
    vars:
      aws_instance-node-instance_type: t2.micro #t2.micro is ignored in destroy, but aws_instance-node-instance_type is required.
      aws_ebs_volume_type: standard
  get_params:
    action: destroy

ccp_gen_cluster_default_params_anchor: &ccp_gen_cluster_default_params
  AWS_ACCESS_KEY_ID: {{tf-machine-access-key-id}}
  AWS_SECRET_ACCESS_KEY: {{tf-machine-secret-access-key}}
  AWS_DEFAULT_REGION: {{aws-region}}
  BUCKET_PATH: clusters/
  BUCKET_NAME: {{tf-bucket-name}}



jobs:

- name: compile_gpdb_centos6
  plan:
  - aggregate:
    - get: gpdb_src
      trigger: true
    - get: gpaddon_src
    - get: centos-gpdb-dev-6
  - task: compile_gpdb
    file: gpdb_src/concourse/tasks/compile_gpdb.yml
    image: centos-gpdb-dev-6
    params:
      IVYREPO_HOST: {{ivyrepo_host}}
      IVYREPO_REALM: {{ivyrepo_realm}}
      IVYREPO_USER: {{ivyrepo_user}}
      IVYREPO_PASSWD: {{ivyrepo_passwd}}
      CONFIGURE_FLAGS: {{configure_flags}}
      TARGET_OS: centos
      TARGET_OS_VERSION: 6
      BLD_TARGETS: "clients loaders"
  - aggregate:
    - put: bin_gpdb6_centos6
      params:
        file: gpdb_artifacts/bin_gpdb.tar.gz

- name: minimal_cluster
  plan:
  - aggregate:
    - get: ccp_src
      tags: ["ccp"]
    - get: perf_src
      tags: ["ccp"]
    - get: gpdb_src
      tags: ["ccp"]
      params:
        submodules:
        - gpMgmt/bin/pythonSrc/ext
      passed: [compile_gpdb_centos6]
    - get: bin_gpdb4_centos6
      tags: ["ccp"]
    - get: bin_gpdb5_centos6
      tags: ["ccp"]
    - get: bin_gpdb6_centos6
      tags: ["ccp"]
      passed: [compile_gpdb_centos6]
      trigger: true
    - get: centos-gpdb-dev-6
      tags: ["ccp"]
  - put: terraform
    tags: ["ccp"]
    params:
      <<: *ccp_default_params
      vars:
        <<: *ccp_default_vars
  - task: gen_cluster
    tags: ["ccp"]
    file: ccp_src/ci/tasks/gen_cluster.yml
    params:
      AWS_ACCESS_KEY_ID: {{tf-machine-access-key-id}}
      AWS_SECRET_ACCESS_KEY: {{tf-machine-secret-access-key}}
      AWS_DEFAULT_REGION: {{aws-region}}
      BUCKET_PATH: clusters/
      BUCKET_NAME: {{tf-bucket-name}}
      platform: centos6
    input_mapping:
      gpdb_binary: {{initial-cluster-gpdb-binary}}

  - task: setup_cluster
    tags: ["ccp"]
    input_mapping:
      new_gpdb_binary: {{upgraded-cluster-gpdb-binary}}
    config:
      platform: linux
      image_resource:
        type: docker-image
        source:
          repository: toolsmiths/ccp
          tag: "7"
      inputs:
      - name: terraform
      - name: ccp_src
      - name: cluster_env_files
      - name: perf_src
      - name: {{upgraded-cluster-gpdb-binary}}
      params:
        DEBUG_UPGRADE: {{enable-debug-output}}
      run:
        path: sh
        args:
        - -c
        - |
          #!/bin/bash

          set -euo pipefail

          # Set the DEBUG_UPGRADE envvar to a nonempty value to get (extremely) verbose
          # output.
          DEBUG_UPGRADE=${DEBUG_UPGRADE:-}

          ./ccp_src/aws/setup_ssh_to_cluster.sh

          DIRNAME=$(dirname "$0")

          cat << EOF
            ############################
            #                          #
            #  New GPDB Installation   #
            #                          #
            ############################
          EOF

          extract_gpdb_tarball() {
              local node_hostname=$1
              local tarball_dir=$2
              # Commonly the incoming binary will be called bin_gpdb.tar.gz. Because many other teams/pipelines tend to use 
              # that naming convention we are not, deliberately. Once the file crosses into our domain, we will not use
              # the conventional name.  This should make clear that we will install any valid binary, not just those that follow
              # the naming convention.
              scp ${tarball_dir}/*.tar.gz $node_hostname:/tmp/gpdb_binary.tar.gz
              ssh -ttn $node_hostname "sudo bash -c \"\
                mkdir -p /usr/local/gpdb_master; \
                tar -xf /tmp/gpdb_binary.tar.gz -C /usr/local/gpdb_master; \
                chown -R gpadmin:gpadmin /usr/local/gpdb_master; \
                sed -ie 's|^GPHOME=.*|GPHOME=/usr/local/gpdb_master|' /usr/local/gpdb_master/greenplum_path.sh ; \
              \""
          }

          create_new_datadir() {
              local node_hostname=$1

              # Create a -new directory for every data directory that already exists.
              # This is what we'll be init'ing the new database into.
              ssh -ttn "$node_hostname" 'sudo bash -c '\''
                  for dir in $(find /data/gpdata/* -maxdepth 0 -type d); do
                      newdir="${dir}-new"

                      mkdir -p "$newdir"
                      chown gpadmin:gpadmin "$newdir"
                  done
              '\'''
          }

          gpinitsystem_for_upgrade() {
              # Stop the old cluster and init a new one.
              ssh -ttn mdw "
                  source /usr/local/greenplum-db-devel/greenplum_path.sh
                  gpstop -a -d /data/gpdata/master/gpseg-1

                  source /usr/local/gpdb_master/greenplum_path.sh
                  sed -e 's|\(/data/gpdata/\w\+\)|\1-new|g' gpinitsystem_config > gpinitsystem_config_new
                  sed -ie 's|MASTER_PORT=5432|MASTER_PORT=6432|g' gpinitsystem_config_new
                  sed -ie 's|PORT_BASE=2|PORT_BASE=3|g' gpinitsystem_config_new
                  gpinitsystem -a -c ~gpadmin/gpinitsystem_config_new -h ~gpadmin/segment_host_list
                  gpstop -a -d /data/gpdata/master-new/gpseg-1
              "
          }

          dump_old_master_query() {
              # Prints the rows generated by the given SQL query to stdout. The query is
              # run on the old master, pre-upgrade.
              ssh -n mdw '
                  source /usr/local/greenplum-db-devel/greenplum_path.sh
                  psql postgres --quiet --no-align --tuples-only -F"'$'\t''" -c "'$1'"
              '
          }

          get_segment_datadirs() {
              # Prints the hostnames and data directories of each primary and mirror: one
              # instance per line, with the hostname and data directory separated by a
              # tab.

              # First try dumping the 6.0 version...
              local q="SELECT hostname, datadir FROM gp_segment_configuration WHERE content <> -1"
              if ! dump_old_master_query "$q" 2>/dev/null; then
                  # ...and then fall back to pre-6.0.
                  q="SELECT hostname, fselocation FROM gp_segment_configuration JOIN pg_catalog.pg_filespace_entry ON (dbid = fsedbid) WHERE content <> -1"
                  dump_old_master_query "$q"
              fi
          }

          gen_environment_scripts() {
              ssh -ttn mdw "cat > ~gpadmin/src_5x.sh <<HERE
          export PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/gpadmin/bin
          export MASTER_DATA_DIRECTORY=/data/gpdata/master/gpseg-1
          export PGPORT=5432
          source /usr/local/greenplum-db-devel/greenplum_path.sh
          alias \"6x\"=\"source ~gpadmin/src_6x.sh\"
          HERE
                  cat > ~gpadmin/src_6x.sh <<HERE
          export PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/gpadmin/bin
          export MASTER_DATA_DIRECTORY=/data/gpdata/master-new/gpseg-1
          export PGPORT=6432
          source /usr/local/gpdb_master/greenplum_path.sh
          alias \"5x\"=\"source ~gpadmin/src_5x.sh\"
          HERE"
          }

          CLUSTER_NAME=$(cat ./terraform*/name)

          NUMBER_OF_NODES=2

          GPDB_TARBALL_DIR=

          set -v

          for ((i=0; i<${NUMBER_OF_NODES}; ++i)); do
            extract_gpdb_tarball ccp-${CLUSTER_NAME}-$i ${GPDB_TARBALL_DIR:-bin_gpdb6_centos6}
            create_new_datadir ccp-${CLUSTER_NAME}-$i
          done

          get_segment_datadirs > /tmp/segment_datadirs.txt
          gpinitsystem_for_upgrade

          gen_environment_scripts

          echo "Finished with setup"
    ensure:
      <<: *set_failed
